x-airflow-common:
  &airflow-common
  image: apache/airflow:2.10.5-python3.11
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:${POSTGRES_PASSWORD:-airflow}@postgres/airflow
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:${POSTGRES_PASSWORD:-airflow}@postgres/airflow
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY:-}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session'
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY:-news-pipeline-key}
    AIRFLOW__WEBSERVER__WEB_SERVER_PORT: '8081'
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'false'
    AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: '60'
    AIRFLOW__CORE__DEFAULT_TIMEZONE: Asia/Seoul
    # 보안 설정
    AIRFLOW__WEBSERVER__ENABLE_PROXY_FIX: 'true'
    AIRFLOW__CORE__SECURE_MODE: 'true'
    AIRFLOW__WEBSERVER__COOKIE_SECURE: 'true'
    AIRFLOW__WEBSERVER__COOKIE_SAMESITE: 'Lax'
    # 성능 설정
    AIRFLOW__SCHEDULER__PARSING_PROCESSES: '2'
    AIRFLOW__CORE__PARALLELISM: '16'
    AIRFLOW__CORE__DAG_CONCURRENCY: '8'
    AIRFLOW__CORE__MAX_ACTIVE_RUNS_PER_DAG: '4'
    # 작업 설정
    AIRFLOW__SCHEDULER__JOB_HEARTBEAT_SEC: '30'
    AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC: '10'
    # 로깅 설정
    AIRFLOW__LOGGING__BASE_LOG_FOLDER: '/opt/airflow/logs'
    AIRFLOW__LOGGING__DAG_PROCESSOR_MANAGER_LOG_LOCATION: '/opt/airflow/logs/dag_processor_manager/dag_processor_manager.log'
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./config:/opt/airflow/config
    - ./models:/opt/airflow/models_storage
    - /var/run/docker.sock:/var/run/docker.sock
  user: "50000:0"
  group_add:
    - "984"
  networks:
    - news-pipeline
  depends_on:
    &airflow-common-depends-on
    postgres:
      condition: service_healthy
  deploy:
    resources:
      limits:
        cpus: "2.0"
        memory: 2G
      reservations:
        cpus: "1.0"
        memory: 1G
  restart: unless-stopped
  healthcheck:
    test: ["CMD", "curl", "--fail", "http://localhost:8081/health"]
    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 30s

services:
  postgres:
    image: postgres:13
    container_name: npl-airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-airflow}
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
      start_period: 5s
    restart: unless-stopped
    networks:
      - news-pipeline
    deploy:
      resources:
        limits:
          cpus: "1.0"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 500M

  airflow-webserver:
    <<: *airflow-common
    container_name: npl-airflow-webserver
    command: webserver
    ports:
      - 8081:8081
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8081/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - news-pipeline
    user: "50000:0"
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    environment:
      <<: *airflow-common-env
      # 추가 보안 설정
      AIRFLOW__WEBSERVER__RBAC: 'true'
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: 'false'
      AIRFLOW__WEBSERVER__INSTANCE_NAME: '뉴스 파이프라인 - 에어플로우'

  airflow-scheduler:
    <<: *airflow-common
    container_name: npl-airflow-scheduler
    command: scheduler
    healthcheck:
      test: ["CMD-SHELL", 'airflow jobs check --job-type SchedulerJob --hostname "$${HOSTNAME}"']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    networks:
      - news-pipeline
    depends_on:
      <<: *airflow-common-depends-on
      airflow-init:
        condition: service_completed_successfully
    environment:
      <<: *airflow-common-env
      # 추가 스케줄러 설정
      AIRFLOW__SCHEDULER__MAX_THREADS: '4'
      AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: '30'

  airflow-init:
    <<: *airflow-common
    container_name: npl-airflow-init
    entrypoint: /bin/bash
    restart: "no"
    healthcheck:
      disable: true
    command:
      - -c
      - |
        mkdir -p /opt/airflow/dags /opt/airflow/logs /opt/airflow/plugins /opt/airflow/config
        chmod -R g+w /opt/airflow/logs /opt/airflow/plugins
        airflow db init && \
        airflow users create \
          --username ${AIRFLOW_ADMIN_USER:-airflow} \
          --password ${AIRFLOW_ADMIN_PASSWORD:-airflow} \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email ${AIRFLOW_ADMIN_EMAIL:-keemgdeok@gmail.com}
          
        echo "Airflow initialization script completed."
        exit 0 # 명시적으로 성공 종료 코드 반환
    networks:
      - news-pipeline
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_ADMIN_USER:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD:-airflow}
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: 512M

networks:
  news-pipeline:
    external: true
    name: news-pipeline

volumes:
  postgres-db-volume: 