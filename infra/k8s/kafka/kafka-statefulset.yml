apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: news-platform
  labels:
    app: kafka
spec:
  serviceName: "kafka-svc"
  replicas: 3
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      terminationGracePeriodSeconds: 300
      securityContext:
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      volumes:
        - name: kafka-config-volume
          configMap:
            name: kafka-config
            items:
              - key: server.properties
                path: server.properties
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.3.0
        ports:
        - containerPort: 9092
          name: kafka-client
        - containerPort: 9093
          name: kafka-internal
        env:
        - name: KAFKA_BROKER_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: KAFKA_ZOOKEEPER_CONNECT
          value: "zookeeper-svc:2181"
        - name: KAFKA_ADVERTISED_LISTENERS
          value: "PLAINTEXT://$(POD_NAME).kafka-svc.$(NAMESPACE).svc.cluster.local:9092,INTERNAL://$(POD_NAME).kafka-svc.$(NAMESPACE).svc.cluster.local:9093"
        - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
          value: "PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT"
        - name: KAFKA_INTER_BROKER_LISTENER_NAME
          value: "INTERNAL"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "false"
        - name: KAFKA_DEFAULT_REPLICATION_FACTOR
          value: "3"
        - name: KAFKA_MIN_INSYNC_REPLICAS
          value: "2"
        - name: KAFKA_NUM_PARTITIONS
          value: "3"
        - name: KAFKA_LOG_RETENTION_HOURS
          value: "168"
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2"
        volumeMounts:
        - name: data
          mountPath: /var/lib/kafka/data
        - name: kafka-config-volume
          mountPath: /etc/kafka/config/server.properties
          subPath: server.properties
        readinessProbe:
          tcpSocket:
            port: kafka-client
          initialDelaySeconds: 15
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        livenessProbe:
          tcpSocket:
            port: kafka-client
          initialDelaySeconds: 30
          periodSeconds: 20
          timeoutSeconds: 5
          failureThreshold: 3
        securityContext:
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "standard"
      resources:
        requests:
          storage: 50Gi
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-svc
  namespace: news-platform
  labels:
    app: kafka
spec:
  ports:
  - port: 9092
    name: kafka-client
  - port: 9093
    name: kafka-internal
  clusterIP: None
  selector:
    app: kafka
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-client-service
  namespace: news-platform
  labels:
    app: kafka
spec:
  type: ClusterIP
  ports:
  - port: 9092
    targetPort: kafka-client
    name: kafka-client
  selector:
    app: kafka
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: kafka-pdb
  namespace: news-platform
spec:
  minAvailable: 2
  selector:
    matchLabels:
    app: kafka 